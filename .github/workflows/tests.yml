name: Integration Tests

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:

jobs:
  tests:
    name: Backend Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Install yq
        run: |
          sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/local/bin/yq
          sudo chmod +x /usr/local/bin/yq

      - name: Setup Kubernetes (k3s) and Kubeconfig
        run: |
          curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--disable=traefik --tls-san host.docker.internal" sh -
          mkdir -p $HOME/.kube
          sudo k3s kubectl config view --raw > $HOME/.kube/config
          sudo chmod 600 $HOME/.kube/config
          timeout 90 bash -c 'until sudo k3s kubectl cluster-info; do sleep 5; done'
          kubectl version
          kubectl get nodes

      - name: Create dummy kubeconfig for CI
        run: |
          # Create a dummy kubeconfig so backend can start without real k8s connection
          cat > backend/kubeconfig.yaml <<EOF
          apiVersion: v1
          kind: Config
          clusters:
          - name: ci-cluster
            cluster:
              server: https://host.docker.internal:6443
              insecure-skip-tls-verify: true
          users:
          - name: ci-user
            user:
              token: "ci-token"
          contexts:
          - name: ci
            context:
              cluster: ci-cluster
              user: ci-user
          current-context: ci
          EOF
          echo "Created dummy kubeconfig for CI"

      - name: Pre-pull base images in parallel
        run: |
          echo "Pre-pulling base images to speed up builds..."
          docker pull python:3.12-slim &
          docker pull alpine:latest &
          docker pull confluentinc/cp-kafka:7.5.0 &
          docker pull confluentinc/cp-zookeeper:7.5.0 &
          docker pull mongo:7 &
          docker pull redis:7-alpine &
          wait
          echo "Base images pulled successfully"

      - name: Modify Docker Compose for CI
        run: |
          cp docker-compose.yaml docker-compose.ci.yaml
          # Drop the frontend service for backend-only tests
          yq eval 'del(.services.frontend)' -i docker-compose.ci.yaml
          # For the backend service (extra_hosts already exists, skip it)
          # Note: backend.environment is a list in docker-compose.yaml
          yq eval '.services.backend.environment += ["TESTING=true"]' -i docker-compose.ci.yaml
          yq eval '.services.backend.environment += ["MONGO_ROOT_USER=root"]' -i docker-compose.ci.yaml
          yq eval '.services.backend.environment += ["MONGO_ROOT_PASSWORD=rootpassword"]' -i docker-compose.ci.yaml
          # Disable OpenTelemetry SDK during tests to avoid exporter retries
          yq eval '.services.backend.environment += ["OTEL_SDK_DISABLED=true"]' -i docker-compose.ci.yaml

          # MongoDB service already has defaults in docker-compose.yaml (root/rootpassword)
          # No need to override them

          # Disable SASL authentication for Kafka and Zookeeper in CI
          yq eval 'del(.services.kafka.environment.KAFKA_OPTS)' -i docker-compose.ci.yaml
          yq eval 'del(.services.zookeeper.environment.KAFKA_OPTS)' -i docker-compose.ci.yaml
          yq eval 'del(.services.zookeeper.environment.ZOOKEEPER_AUTH_PROVIDER_1)' -i docker-compose.ci.yaml
          yq eval '.services.kafka.volumes = [.services.kafka.volumes[] | select(. | contains("jaas.conf") | not)]' -i docker-compose.ci.yaml
          yq eval '.services.zookeeper.volumes = [.services.zookeeper.volumes[] | select(. | contains("/etc/kafka") | not)]' -i docker-compose.ci.yaml

          # Simplify Zookeeper for CI
          yq eval '.services.zookeeper.environment.ZOOKEEPER_4LW_COMMANDS_WHITELIST = "ruok,srvr"' -i docker-compose.ci.yaml
          # Disable zookeeper healthcheck in CI (use service_started instead)
          yq eval 'del(.services.zookeeper.healthcheck)' -i docker-compose.ci.yaml
          # Make Kafka start as soon as Zookeeper starts (not healthy)
          yq eval '.services.kafka.depends_on.zookeeper.condition = "service_started"' -i docker-compose.ci.yaml

          # For the cert-generator service
          # Check if extra_hosts exists, if not create it as a list
          yq eval 'select(.services."cert-generator".extra_hosts == null).services."cert-generator".extra_hosts = []' -i docker-compose.ci.yaml
          yq eval '.services."cert-generator".extra_hosts += ["host.docker.internal:host-gateway"]' -i docker-compose.ci.yaml
          yq eval '.services."cert-generator".environment += ["CI=true"]' -i docker-compose.ci.yaml
          yq eval '.services."cert-generator".volumes += [env(HOME) + "/.kube/config:/root/.kube/config:ro"]' -i docker-compose.ci.yaml

          echo "--- Modified docker-compose.ci.yaml ---"
          cat docker-compose.ci.yaml
          echo "------------------------------------"

      - name: Build services with optimized cache
        uses: docker/bake-action@v6
        with:
          source: .
          files: docker-compose.ci.yaml
          load: true
          set: |
            *.cache-from=type=gha,scope=buildkit-${{ github.repository }}-${{ github.ref_name }}
            *.cache-from=type=gha,scope=buildkit-${{ github.repository }}-main
            *.cache-to=type=gha,mode=max,scope=buildkit-${{ github.repository }}-${{ github.ref_name }}
            *.pull=true

      - name: Start services
        run: |
            echo "Starting services (images already built with cache)..."
            docker compose -f docker-compose.ci.yaml up -d --remove-orphans || \
            (
              echo "::error::Docker Compose failed to start. Dumping all logs..."
              docker compose -f docker-compose.ci.yaml logs
              exit 1
            )

            echo "Services started. Waiting for stabilization..."
            sleep 45

            echo "Final status of all containers:"
            docker compose -f docker-compose.ci.yaml ps

            echo "Checking cert-generator logs:"
            docker compose -f docker-compose.ci.yaml logs cert-generator || echo "cert-generator not found or exited"

            echo "Checking backend container status:"
            docker compose -f docker-compose.ci.yaml ps backend

            echo "Checking backend logs:"
            docker compose -f docker-compose.ci.yaml logs backend || echo "backend not found"

            # Explicitly check for containers that have exited
            if docker compose -f docker-compose.ci.yaml ps | grep -q 'Exit'; then
              echo "::error::One or more containers have exited unexpectedly. See logs above."
              docker compose -f docker-compose.ci.yaml logs --no-color
              exit 1
            fi

      - name: Wait for backend to be healthy
        run: |
          timeout 300 bash -c 'until curl -k https://127.0.0.1:443/api/v1/health -o /dev/null; do \
            echo "Retrying backend health check..."; \
            sleep 5; \
          done'
          echo "Backend is healthy!"

      # Frontend is excluded in backend-only CI; skip UI readiness

      - name: Check K8s setup status after startup
        run: |
          kubectl get pods -A -o wide
          kubectl get services -A -o wide
          kubectl get sa -n default
          kubectl get roles -n default
          kubectl get rolebindings -n default

      - name: Set up uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "backend/uv.lock"

      - name: Install Python and dependencies
        run: |
          cd backend
          uv python install 3.12
          uv sync --frozen

      - name: Run backend tests with coverage
        timeout-minutes: 5
        env:
          BACKEND_BASE_URL: https://127.0.0.1:443
          # Use default MongoDB credentials for CI
          MONGO_ROOT_USER: root
          MONGO_ROOT_PASSWORD: rootpassword
          MONGODB_HOST: 127.0.0.1
          MONGODB_PORT: 27017
          # Explicit URL with default credentials
          MONGODB_URL: mongodb://root:rootpassword@127.0.0.1:27017/?authSource=admin
          # Optional isolation for Schema Registry subjects (fresh registry in CI, but safe to set)
          SCHEMA_SUBJECT_PREFIX: "ci.${{ github.run_id }}."
        run: |
          cd backend
          echo "Using BACKEND_BASE_URL=$BACKEND_BASE_URL"
          echo "Using SCHEMA_SUBJECT_PREFIX=$SCHEMA_SUBJECT_PREFIX"
          echo "MongoDB connection will use default CI credentials"
          uv run pytest tests/integration tests/unit -v --cov=app --cov-branch --cov-report=xml --cov-report=term --cov-report=term-missing

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: backend/coverage.xml
          flags: backend
          name: backend-coverage
          slug: HardMax71/Integr8sCode
          fail_ci_if_error: false

      - name: Collect logs
        if: always()
        run: |
          mkdir -p logs
          docker compose -f docker-compose.ci.yaml logs > logs/docker-compose.log
          docker compose -f docker-compose.ci.yaml logs cert-generator > logs/cert-generator.log
          docker compose -f docker-compose.ci.yaml logs backend > logs/backend.log
          docker compose -f docker-compose.ci.yaml logs mongo > logs/mongo.log
          kubectl get events --sort-by='.metadata.creationTimestamp' > logs/k8s-events.log
          kubectl get pods -A -o wide > logs/k8s-pods-final.log
          kubectl describe pods -A > logs/k8s-describe-pods-final.log

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-logs
          path: logs/
