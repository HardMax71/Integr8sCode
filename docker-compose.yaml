services:
  shared-ca:
    image: alpine:latest
    volumes:
      - shared_ca:/shared_ca
    command: sh -c "mkdir -p /shared_ca && chmod 777 /shared_ca && echo 'Shared CA directory ready' && sleep 2"
    networks:
      - app-network

  cert-generator:
    build:
      context: ./cert-generator
      dockerfile: Dockerfile
    volumes:
      - ./backend/certs:/backend-certs
      - ./frontend/certs:/frontend-certs
      - ~/.kube:/root/.kube
      - shared_ca:/shared_ca
      - ./backend:/backend
    environment:
       - SHARED_CA_DIR=/shared_ca
       - BACKEND_CERT_DIR=/backend-certs
       - FRONTEND_CERT_DIR=/frontend-certs
       - USE_DOCKER_HOST=true
    restart: "no"
    network_mode: host
    depends_on:
      shared-ca:
        condition: service_completed_successfully

  mongo:
    image: mongo:4.4
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-root}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-rootpassword}
      MONGO_INITDB_DATABASE: integr8scode
    volumes:
      - mongo_data:/data/db
    networks:
      - app-network
    container_name: mongo
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo localhost/integr8scode -u ${MONGO_ROOT_USER:-root} -p ${MONGO_ROOT_PASSWORD:-rootpassword} --authenticationDatabase admin --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    depends_on:
      cert-generator:
        condition: service_completed_successfully
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_started
    volumes:
      - ./backend:/app
      - ./backend/certs:/app/certs:ro
      - shared_ca:/shared_ca:ro
      - ./backend/kubeconfig.yaml:/app/kubeconfig.yaml:ro
    ports:
      - "443:443"
    networks:
      - app-network
    container_name: backend
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - ./backend/.env
    environment:
      - SERVER_HOST=0.0.0.0
    healthcheck:
      test: [ "CMD", "curl", "-k", "https://localhost/api/v1/health" ]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 5s

  frontend:
    container_name: frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      cert-generator:
        condition: service_completed_successfully
      backend:
        condition: service_healthy
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - ./frontend/certs:/app/certs:ro
      - shared_ca:/shared_ca:ro
    ports:
      - "5001:5001"
    networks:
      - app-network
    environment:
      - VITE_BACKEND_URL=https://backend:443
      - NODE_EXTRA_CA_CERTS=/shared_ca/mkcert-ca.pem

  prometheus:
    container_name: prometheus
    image: prom/prometheus:v2.45.0
    ports:
      - "9090:9090"
    volumes:
      - ./backend/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=5GB'
      - '--query.max-samples=50000000'
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
          cpus: '0.5'

  alertmanager:
    container_name: alertmanager
    image: prom/alertmanager:v0.25.0
    ports:
      - "9093:9093"
    volumes:
      - ./backend/alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - app-network

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    user: "472"
    ports:
      - "3000:3000"
    volumes:
      - ./backend/grafana/grafana.ini:/etc/grafana/grafana.ini:ro
      - ./backend/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    depends_on:
      prometheus:
        condition: service_started
    networks:
      - app-network
    environment:
      - GF_LOG_LEVEL=warn

  # Kafka Infrastructure for Event-Driven Design
  # Certificate generator for Zookeeper/Kafka SSL
  zookeeper-certgen:
    build:
      context: ./backend/zookeeper
      dockerfile: Dockerfile.certgen
    container_name: zookeeper-certgen
    volumes:
      - zookeeper_certs:/certs
    networks:
      - app-network
    restart: "no"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    depends_on:
      zookeeper-certgen:
        condition: service_completed_successfully
    environment:
      # Basic configuration
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SECURE_CLIENT_PORT: 2281
      ZOOKEEPER_TICK_TIME: 2000
      
      # Production settings
      ZOOKEEPER_MAX_CLIENT_CNXNS: 60
      ZOOKEEPER_INIT_LIMIT: 10
      ZOOKEEPER_SYNC_LIMIT: 5
      
      # Security settings
      # ZOOKEEPER_AUTH_PROVIDER_1: org.apache.zookeeper.server.auth.DigestAuthenticationProvider
      ZOOKEEPER_SERVER_CNXN_FACTORY: org.apache.zookeeper.server.NettyServerCnxnFactory
      KAFKA_OPTS: '-Dzookeeper.serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory -Dzookeeper.4lw.commands.whitelist=*'
      ZOOKEEPER_SSL_KEYSTORE_LOCATION: '/etc/kafka/certs/zookeeper.keystore.jks'
      ZOOKEEPER_SSL_KEYSTORE_PASSWORD: 'zookeeper_keystore_password'
      ZOOKEEPER_SSL_TRUSTSTORE_LOCATION: '/etc/kafka/certs/zookeeper.truststore.jks'
      ZOOKEEPER_SSL_TRUSTSTORE_PASSWORD: 'zookeeper_truststore_password'
      ZOOKEEPER_SSL_CLIENTAUTH: 'need'
      ZOOKEEPER_SSL_QUORUM: 'true'
      
      # 4lw commands whitelist (minimal for security)
      ZOOKEEPER_4LW_COMMANDS_WHITELIST: '*'
      
      # Autopurge settings
      ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT: 3
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: 24
      
      # JVM settings for production
      KAFKA_HEAP_OPTS: '-Xms1G -Xmx1G'
      KAFKA_JVM_PERFORMANCE_OPTS: '-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:+ParallelRefProcEnabled -Djute.maxbuffer=4194304'
      
      # Logging
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: 'WARN'
      ZOOKEEPER_LOG4J_LOGGERS: 'org.apache.zookeeper.server.auth=INFO,org.apache.zookeeper.audit=INFO'
      
      # Disable admin server for security
      ZOOKEEPER_ADMIN_ENABLE_SERVER: 'false'
      ZOOKEEPER_ADMIN_SERVER_PORT: 0
      
      # Metrics
      ZOOKEEPER_METRICS_PROVIDER_CLASS_NAME: org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
      ZOOKEEPER_METRICS_PROVIDER_HTTP_PORT: 7070
      
    volumes:
      - ./backend/zookeeper/conf:/etc/kafka/conf:ro
      - ./backend/zookeeper/secrets:/etc/kafka/secrets:ro
      - zookeeper_certs:/etc/kafka/certs:ro
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
      - zookeeper_logs:/var/log/zookeeper
    ports:
      - "2181:2181"
      - "2281:2281"  # Secure client port
      - "7070:7070"  # Metrics port
    networks:
      - app-network
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181 | grep imok"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'  # Needed for initial setup
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      
      # Security settings for Zookeeper connection
      # KAFKA_OPTS: '-Djava.security.auth.login.config=/etc/kafka/secrets/kafka_jaas.conf'
      KAFKA_ZOOKEEPER_SET_ACL: 'false'
      # KAFKA_AUTHORIZER_CLASS_NAME: 'kafka.security.authorizer.AclAuthorizer'
      # KAFKA_SUPER_USERS: 'User:admin;User:kafka'
      
      # Production settings
      KAFKA_COMPRESSION_TYPE: 'gzip'
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
      # Log settings
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: 'delete'
      
      # JVM settings
      KAFKA_HEAP_OPTS: '-Xms2G -Xmx2G'
      KAFKA_JVM_PERFORMANCE_OPTS: '-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true'
      
    volumes:
      - ./backend/zookeeper/secrets/kafka_jaas.conf:/etc/kafka/secrets/kafka_jaas.conf:ro
      - kafka_data:/var/lib/kafka/data
      - kafka_logs:/var/log/kafka
    networks:
      - app-network
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - app-network

  kafdrop:
    image: obsidiandynamics/kafdrop:3.31.0
    container_name: kafdrop
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:29092
      JVM_OPTS: "-Xms256M -Xmx512M"
      SCHEMAREGISTRY_CONNECT: http://schema-registry:8081
    networks:
      - app-network

  # Kafka topic initialization
  kafka-init:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_started
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
    command: ["python", "-m", "scripts.create_topics"]
    networks:
      - app-network
    restart: "no"  # Run once and exit

  # Event-driven workers
  coordinator:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.coordinator
    container_name: coordinator
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongo:
        condition: service_started
      jaeger:
        condition: service_started
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER:-root}:${MONGO_ROOT_PASSWORD:-rootpassword}@mongo:27017/integr8scode?authSource=admin
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - TRACING_SERVICE_NAME=execution-coordinator
      - KAFKA_CONSUMER_GROUP_ID=execution-coordinator
    networks:
      - app-network
    restart: unless-stopped

  k8s-worker:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.k8s_worker
    container_name: k8s-worker
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongo:
        condition: service_started
      jaeger:
        condition: service_started
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER:-root}:${MONGO_ROOT_PASSWORD:-rootpassword}@mongo:27017/integr8scode?authSource=admin
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - TRACING_SERVICE_NAME=k8s-worker
      - K8S_NAMESPACE=integr8scode
      - KUBECONFIG=/app/kubeconfig.yaml
      - KAFKA_CONSUMER_GROUP_ID=k8s-worker
    volumes:
      - ./backend/kubeconfig.yaml:/app/kubeconfig.yaml:ro
    networks:
      - app-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  pod-monitor:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.pod_monitor
    container_name: pod-monitor
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      jaeger:
        condition: service_started
    env_file:
      - ./backend/.env
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - TRACING_SERVICE_NAME=pod-monitor
      - K8S_NAMESPACE=integr8scode
      - KUBECONFIG=/app/kubeconfig.yaml
      - KAFKA_CONSUMER_GROUP_ID=pod-monitor
    volumes:
      - ./backend/kubeconfig.yaml:/app/kubeconfig.yaml:ro
    networks:
      - app-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  result-processor:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.result_processor
    container_name: result-processor
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongo:
        condition: service_started
      jaeger:
        condition: service_started
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER:-root}:${MONGO_ROOT_PASSWORD:-rootpassword}@mongo:27017/integr8scode?authSource=admin
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - TRACING_SERVICE_NAME=result-processor
      - KAFKA_CONSUMER_GROUP_ID=result-processor-group
    volumes:
      - ./backend/kubeconfig.yaml:/root/.kube/config:ro
    networks:
      - app-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  saga-orchestrator:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.saga_orchestrator
    container_name: saga-orchestrator
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongo:
        condition: service_started
      jaeger:
        condition: service_started
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER:-root}:${MONGO_ROOT_PASSWORD:-rootpassword}@mongo:27017/integr8scode?authSource=admin
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - TRACING_SERVICE_NAME=saga-orchestrator
    networks:
      - app-network
    restart: unless-stopped

  # Distributed tracing with Jaeger
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: jaeger
    ports:
      - "5775:5775/udp"   # Zipkin/thrift compact
      - "6831:6831/udp"   # Thrift compact
      - "6832:6832/udp"   # Thrift binary
      - "5778:5778"       # HTTP config
      - "16686:16686"     # Jaeger UI
      - "14268:14268"     # HTTP collector
      - "14250:14250"     # gRPC collector
      - "9411:9411"       # Zipkin compatible endpoint
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - app-network

  # Event replay service
  event-replay:
    build:
      context: ./backend
      dockerfile: workers/Dockerfile.event_replay
    container_name: event-replay
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongo:
        condition: service_started
    command: python workers/run_event_replay.py
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER:-root}:${MONGO_ROOT_PASSWORD:-rootpassword}@mongo:27017/integr8scode?authSource=admin
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - SERVICE_NAME=event-replay
      - TRACING_SERVICE_NAME=event-replay
      - ENABLE_TRACING=true
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
    networks:
      - app-network
    restart: unless-stopped

volumes:
  mongo_data:
  prometheus_data:
  grafana_data:
  shared_ca:
  kafka_data:
  kafka_logs:
  zookeeper_data:
  zookeeper_log:
  zookeeper_logs:
  zookeeper_certs:

networks:
  app-network:
    driver: bridge